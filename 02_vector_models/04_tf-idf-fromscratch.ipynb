{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bag of words - turns all documents into a single vector of words\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import nltk \n",
    "\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/faa/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    labels\n",
       "0  Ad sales boost Time Warner profit\\n\\nQuarterly...  business\n",
       "1  Dollar gains on Greenspan speech\\n\\nThe dollar...  business\n",
       "2  Yukos unit buyer faces loan claim\\n\\nThe owner...  business\n",
       "3  High fuel prices hit BA's profits\\n\\nBritish A...  business\n",
       "4  Pernod takeover talk lifts Domecq\\n\\nShares in...  business"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the punkt tokenizer for sentence splitting\n",
    "nltk.download('punkt')\n",
    "\n",
    "df = pd.read_csv('bbc_text_cls.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of lists for each document (words are encoded as 0-based indexes)\n",
    "idx = 0 \n",
    "word2idx = {}\n",
    "tokenized_docs = []\n",
    "for doc in df['text']:\n",
    "    words = word_tokenize(doc.lower())\n",
    "    # int values that map to the word in word2idx\n",
    "    doc_as_int = []\n",
    "    for word in words: \n",
    "        if word not in word2idx: \n",
    "            # adds new word\n",
    "            word2idx[word] = idx\n",
    "            # assignes it a new index\n",
    "            idx += 1\n",
    "\n",
    "        # creates a list of the word indexes in the document\n",
    "        doc_as_int.append(word2idx[word])\n",
    "\n",
    "    # creates a list of lists (all documents as lists of word indexes)\n",
    "    tokenized_docs.append(doc_as_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse mapping, converts index to a word\n",
    "idx2word = {v:k for k, v in word2idx.items()}\n",
    "\n",
    "# number of rows in df (documents)\n",
    "N = len(df['text'])\n",
    "\n",
    "# number of unique words in the corpus\n",
    "V = len(word2idx)\n",
    "\n",
    "# term-frequency matrix, how many times a word appears in a document\n",
    "tf = np.zeros((N, V))\n",
    "\n",
    "# populating, i = document number, doc_as_int = list of words as indexes in the document\n",
    "for i, doc_as_int in enumerate(tokenized_docs): \n",
    "    for j in doc_as_int: \n",
    "        # j = word index, i = document number\n",
    "        tf[i, j] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute idf \n",
    "document_freq = np.sum(tf > 0, axis=0) # for each column (word), sums all documents where a word appears\n",
    "idf = np.log(N / document_freq) # (V,1) sized vector \n",
    "\n",
    "# compute tf-idf\n",
    "tf_idf = tf * idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  politics\n",
      "Text:  Blair prepares to name poll date\n",
      "Top 5 terms: \n",
      "parliament 15.821087061651685\n",
      "election 14.077320173345495\n",
      "easter 13.217799811864461\n",
      "dissolve 13.217799811864461\n",
      "blair 12.572776718550651\n"
     ]
    }
   ],
   "source": [
    "# consistent results across runs\n",
    "np.random.seed(123)\n",
    "\n",
    "# pick a random document, show the top 5 terms with the highest tf-idf score\n",
    "# random int\n",
    "i = np.random.choice(N)\n",
    "\n",
    "# df at the random index\n",
    "row = df.iloc[i]\n",
    "\n",
    "print('Label: ', row['labels'])\n",
    "print('Text: ', row['text'].split('\\n', 1)[0])\n",
    "print('Top 5 terms: ')\n",
    "\n",
    "scores = tf_idf[i]\n",
    "# desc order, indices \n",
    "indices = (-scores).argsort()\n",
    "\n",
    "for j in indices[:5]:\n",
    "    print(idx2word[j], scores[j])\n",
    "\n",
    "# higher score = more important (appears less often in the corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2 (main, Feb 16 2023, 02:55:59) [Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
