{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 16:39:20.739001: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.utils import shuffle\n",
    "from datetime import datetime \n",
    "\n",
    "from keras.models import Model \n",
    "from keras.layers import Input, Embedding, Dot, Add, Flatten \n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>movie_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>3.5</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>3.5</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>3.5</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000258</th>\n",
       "      <td>20000258</td>\n",
       "      <td>138492</td>\n",
       "      <td>68954</td>\n",
       "      <td>4.5</td>\n",
       "      <td>13821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000259</th>\n",
       "      <td>20000259</td>\n",
       "      <td>138492</td>\n",
       "      <td>69526</td>\n",
       "      <td>4.5</td>\n",
       "      <td>13929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000260</th>\n",
       "      <td>20000260</td>\n",
       "      <td>138492</td>\n",
       "      <td>69644</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000261</th>\n",
       "      <td>20000261</td>\n",
       "      <td>138492</td>\n",
       "      <td>70286</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000262</th>\n",
       "      <td>20000262</td>\n",
       "      <td>138492</td>\n",
       "      <td>71619</td>\n",
       "      <td>2.5</td>\n",
       "      <td>14344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000263 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0  userId  movieId  rating  movie_idx\n",
       "0                  0       0        2     3.5          2\n",
       "1                  1       0       29     3.5         29\n",
       "2                  2       0       32     3.5         32\n",
       "3                  3       0       47     3.5         47\n",
       "4                  4       0       50     3.5         50\n",
       "...              ...     ...      ...     ...        ...\n",
       "20000258    20000258  138492    68954     4.5      13821\n",
       "20000259    20000259  138492    69526     4.5      13929\n",
       "20000260    20000260  138492    69644     3.0      13942\n",
       "20000261    20000261  138492    70286     5.0      14060\n",
       "20000262    20000262  138492    71619     2.5      14344\n",
       "\n",
       "[20000263 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/edited_ratings.csv\")\n",
    "df['userId'] = df['userId'] + 1\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = df.userId.max() + 1 # number of users \n",
    "M = df.movie_idx.max() + 1 # number of movies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split in train and test \n",
    "df = shuffle(df) \n",
    "cutoff = int(0.8*len(df))\n",
    "df_train = df.iloc[:cutoff] \n",
    "df_test = df.iloc[cutoff:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init vars \n",
    "K = 10 # latent dimensionality \n",
    "mu = df_train.rating.mean() \n",
    "epoch = 25\n",
    "reg = 0 # regularization penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras model \n",
    "u = Input(shape=(1, ))\n",
    "m = Input(shape=(1, ))\n",
    "u_embedding = Embedding(N, K, embeddings_regularizer=l2(reg))(u) # (N, 1, K)  \n",
    "m_embedding = Embedding(M, K, embeddings_regularizer=l2(reg))(m) # (M, 1, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_bias = Embedding(N, 1, embeddings_regularizer=l2(reg))(u) # (N, 1, 1)\n",
    "m_bias = Embedding(M, 1, embeddings_regularizer=l2(reg))(m) # (N, 1, 1) \n",
    "x = Dot(axes=2)([u_embedding, m_embedding])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Add()([x, u_bias, m_bias])\n",
    "x = Flatten()(x) # (N, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/faa/anaconda3/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[u, m], outputs=x) \n",
    "model.compile(loss='mse', optimizer=SGD(lr=0.01, momentum=0.9), metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "125002/125002 [==============================] - 293s 2ms/step - loss: 0.8691 - mse: 0.8691 - val_loss: 0.8150 - val_mse: 0.8150\n",
      "Epoch 2/25\n",
      "125002/125002 [==============================] - 292s 2ms/step - loss: 0.7966 - mse: 0.7966 - val_loss: 0.7847 - val_mse: 0.7847\n",
      "Epoch 3/25\n",
      "125002/125002 [==============================] - 313s 3ms/step - loss: 0.7743 - mse: 0.7743 - val_loss: 0.7702 - val_mse: 0.7702\n",
      "Epoch 4/25\n",
      " 66476/125002 [==============>...............] - ETA: 2:10 - loss: 0.7640 - mse: 0.7640"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m r \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m      2\u001b[0m     x \u001b[39m=\u001b[39;49m [df_train\u001b[39m.\u001b[39;49muserId\u001b[39m.\u001b[39;49mvalues, df_train\u001b[39m.\u001b[39;49mmovie_idx\u001b[39m.\u001b[39;49mvalues], \n\u001b[1;32m      3\u001b[0m     y \u001b[39m=\u001b[39;49m [df_train\u001b[39m.\u001b[39;49mrating\u001b[39m.\u001b[39;49mvalues \u001b[39m-\u001b[39;49m mu], \n\u001b[1;32m      4\u001b[0m     epochs\u001b[39m=\u001b[39;49mepoch, \n\u001b[1;32m      5\u001b[0m     batch_size\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m, \n\u001b[1;32m      6\u001b[0m     validation_data\u001b[39m=\u001b[39;49m(\n\u001b[1;32m      7\u001b[0m     [df_test\u001b[39m.\u001b[39;49muserId\u001b[39m.\u001b[39;49mvalues, df_test\u001b[39m.\u001b[39;49mmovie_idx\u001b[39m.\u001b[39;49mvalues], \n\u001b[1;32m      8\u001b[0m     df_test\u001b[39m.\u001b[39;49mrating\u001b[39m.\u001b[39;49mvalues \u001b[39m-\u001b[39;49m mu\n\u001b[1;32m      9\u001b[0m     )\n\u001b[1;32m     10\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/engine/training.py:1555\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1551\u001b[0m \u001b[39mwith\u001b[39;00m data_handler\u001b[39m.\u001b[39mcatch_stop_iteration():\n\u001b[1;32m   1552\u001b[0m     data_handler\u001b[39m.\u001b[39m_initial_step \u001b[39m=\u001b[39m data_handler\u001b[39m.\u001b[39m_initial_step \u001b[39mor\u001b[39;00m (\n\u001b[1;32m   1553\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_load_initial_step_from_ckpt()\n\u001b[1;32m   1554\u001b[0m     )\n\u001b[0;32m-> 1555\u001b[0m     \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39msteps():\n\u001b[1;32m   1556\u001b[0m         \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m             epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m             _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m         ):\n\u001b[1;32m   1563\u001b[0m             callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/engine/data_adapter.py:1374\u001b[0m, in \u001b[0;36mDataHandler.steps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_insufficient_data:  \u001b[39m# Set by `catch_stop_iteration`.\u001b[39;00m\n\u001b[1;32m   1373\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m-> 1374\u001b[0m original_spe \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_steps_per_execution\u001b[39m.\u001b[39;49mnumpy()\u001b[39m.\u001b[39mitem()\n\u001b[1;32m   1375\u001b[0m can_run_full_execution \u001b[39m=\u001b[39m (\n\u001b[1;32m   1376\u001b[0m     original_spe \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1377\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_steps \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1378\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_steps \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_step \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m original_spe\n\u001b[1;32m   1379\u001b[0m )\n\u001b[1;32m   1381\u001b[0m \u001b[39mif\u001b[39;00m can_run_full_execution:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorflow/python/ops/resource_variable_ops.py:637\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnumpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    636\u001b[0m   \u001b[39mif\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 637\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread_value()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m    638\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    639\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorflow/python/ops/resource_variable_ops.py:728\u001b[0m, in \u001b[0;36mBaseResourceVariable.read_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    725\u001b[0m   value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_read_variable_op()\n\u001b[1;32m    726\u001b[0m \u001b[39m# Return an identity so it can get placed on whatever device the context\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[39m# specifies instead of the device where the variable is.\u001b[39;00m\n\u001b[0;32m--> 728\u001b[0m \u001b[39mreturn\u001b[39;00m array_ops\u001b[39m.\u001b[39;49midentity(value)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorflow/python/ops/array_ops.py:294\u001b[0m, in \u001b[0;36midentity\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[39mif\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly() \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39minput\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mgraph\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    291\u001b[0m   \u001b[39m# Make sure we get an input with handle data attached from resource\u001b[39;00m\n\u001b[1;32m    292\u001b[0m   \u001b[39m# variables. Variables have correct handle data when graph building.\u001b[39;00m\n\u001b[1;32m    293\u001b[0m   \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mconvert_to_tensor(\u001b[39minput\u001b[39m)\n\u001b[0;32m--> 294\u001b[0m ret \u001b[39m=\u001b[39m gen_array_ops\u001b[39m.\u001b[39;49midentity(\u001b[39minput\u001b[39;49m, name\u001b[39m=\u001b[39;49mname)\n\u001b[1;32m    295\u001b[0m \u001b[39m# Propagate handle data for happier shape inference for resource variables.\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39minput\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_handle_data\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/tensorflow/python/ops/gen_array_ops.py:4069\u001b[0m, in \u001b[0;36midentity\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m   4067\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[1;32m   4068\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 4069\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[1;32m   4070\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mIdentity\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, \u001b[39minput\u001b[39;49m)\n\u001b[1;32m   4071\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[1;32m   4072\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "r = model.fit(\n",
    "    x = [df_train.userId.values, df_train.movie_idx.values], \n",
    "    y = [df_train.rating.values - mu], \n",
    "    epochs=epoch, \n",
    "    batch_size=128, \n",
    "    validation_data=(\n",
    "    [df_test.userId.values, df_test.movie_idx.values], \n",
    "    df_test.rating.values - mu\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot losses \n",
    "plt.plot(r.history['loss'], label = \"train loss\")\n",
    "plt.plot(r.history['val_loss'], label=\"test loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot mse \n",
    "plt.plot(r.history['mean_squared_error'], label=\"train mse\")\n",
    "plt.plot(r.history['val_mean_sqared_error'], label='test mse')\n",
    "plt.legend() \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
