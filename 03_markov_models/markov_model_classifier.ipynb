{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘./data/robert_frost.txt’ already there; not retrieving.\n",
      "\n",
      "File ‘./data/edgar_allan_poe.txt’ already there; not retrieving.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -P ./data/ -nc https://raw.githubusercontent.com/lazyprogrammer/machine_learning_examples/master/hmm_class/robert_frost.txt\n",
    "!wget -P ./data/ -nc https://raw.githubusercontent.com/lazyprogrammer/machine_learning_examples/master/hmm_class/edgar_allan_poe.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import string \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files = [\n",
    "    './data/robert_frost.txt',\n",
    "    './data/edgar_allan_poe.txt',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two roads diverged in a yellow wood,\n",
      "And sorry I could not travel both\n",
      "And be one traveler, long I stood\n",
      "And looked down one as far as I could\n",
      "To where it bent in the undergrowth; \n",
      "\n",
      "Then took the other, as just as fair,\n",
      "And having perhaps the better claim\n",
      "Because it was grassy and wanted wear,\n",
      "Though as for that the passing there\n"
     ]
    }
   ],
   "source": [
    "!head -n 10 ./data/robert_frost.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LO! Death hath rear'd himself a throne\n",
      "In a strange city, all alone,\n",
      "Far down within the dim west\n",
      "Where the good, and the bad, and the worst, and the best,\n",
      "Have gone to their eternal rest.\n",
      " \n",
      "There shrines, and palaces, and towers\n",
      "Are not like any thing of ours\n",
      "Oh no! O no! ours never loom\n",
      "To heaven with that ungodly gloom!\n"
     ]
    }
   ],
   "source": [
    "!head -n 10 ./data/edgar_allan_poe.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/robert_frost.txt corresponds to 0\n",
      "./data/edgar_allan_poe.txt corresponds to 1\n"
     ]
    }
   ],
   "source": [
    "# collect data \n",
    "input_texts = []\n",
    "labels = []\n",
    "\n",
    "for label, f in enumerate(input_files): \n",
    "    print(f\"{f} corresponds to {label}\")\n",
    "\n",
    "    for line in open(f):\n",
    "        # remove tabs / newlines \n",
    "        line = line.rstrip().lower() \n",
    "\n",
    "        if line:\n",
    "            # remove punctuation\n",
    "            line = line.translate(str.maketrans('', '', string.punctuation)) \n",
    "\n",
    "            input_texts.append(line) \n",
    "            labels.append(label) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text, test_text, Ytrain, Ytest = train_test_split(input_texts, labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1615, 539)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Ytrain) , len(Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['more of the salt wherewith theyre to be salted',\n",
       " 'or creaking with a buggy load of grain',\n",
       " 'here once through an alley titanic',\n",
       " 'though once we had journeyed down here',\n",
       " 'at thy softmurmured words let there be light']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 1, 1]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train test split shuffles the dataset, so random authors here\n",
    "Ytrain[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1 \n",
    "# unknown token idx is 0, known words start at 1\n",
    "word2idx = {'<unk>' : 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populate word2idx \n",
    "for text in train_text: \n",
    "    tokens = text.split() \n",
    "\n",
    "    for token in tokens: \n",
    "        if token not in word2idx: \n",
    "            word2idx[token] = idx\n",
    "            idx += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<unk>': 0,\n",
       " 'more': 1,\n",
       " 'of': 2,\n",
       " 'the': 3,\n",
       " 'salt': 4,\n",
       " 'wherewith': 5,\n",
       " 'theyre': 6,\n",
       " 'to': 7,\n",
       " 'be': 8,\n",
       " 'salted': 9,\n",
       " 'or': 10,\n",
       " 'creaking': 11,\n",
       " 'with': 12,\n",
       " 'a': 13,\n",
       " 'buggy': 14,\n",
       " 'load': 15,\n",
       " 'grain': 16,\n",
       " 'here': 17,\n",
       " 'once': 18,\n",
       " 'through': 19,\n",
       " 'an': 20,\n",
       " 'alley': 21,\n",
       " 'titanic': 22,\n",
       " 'though': 23,\n",
       " 'we': 24,\n",
       " 'had': 25,\n",
       " 'journeyed': 26,\n",
       " 'down': 27,\n",
       " 'at': 28,\n",
       " 'thy': 29,\n",
       " 'softmurmured': 30,\n",
       " 'words': 31,\n",
       " 'let': 32,\n",
       " 'there': 33,\n",
       " 'light': 34,\n",
       " 'i': 35,\n",
       " 'cant': 36,\n",
       " 'say': 37,\n",
       " 'hes': 38,\n",
       " 'much': 39,\n",
       " 'help': 40,\n",
       " 'gentlest': 41,\n",
       " 'all': 42,\n",
       " 'gentle': 43,\n",
       " 'names': 44,\n",
       " 'dost': 45,\n",
       " 'take': 46,\n",
       " 'gnaws': 47,\n",
       " 'in': 48,\n",
       " 'stable': 49,\n",
       " 'aint': 50,\n",
       " 'no': 51,\n",
       " 'proof': 52,\n",
       " 'me': 53,\n",
       " 'but': 54,\n",
       " 'wont': 55,\n",
       " 'should': 56,\n",
       " 'burned': 57,\n",
       " 'stake': 58,\n",
       " 'something': 59,\n",
       " 'ill': 60,\n",
       " 'tell': 61,\n",
       " 'you': 62,\n",
       " 'what': 63,\n",
       " 'voices': 64,\n",
       " 'really': 65,\n",
       " 'own': 66,\n",
       " 'makes': 67,\n",
       " 'my': 68,\n",
       " 'head': 69,\n",
       " 'spin': 70,\n",
       " 'not': 71,\n",
       " 'long': 72,\n",
       " 'ago': 73,\n",
       " 'writer': 74,\n",
       " 'these': 75,\n",
       " 'lines': 76,\n",
       " 'so': 77,\n",
       " 'than': 78,\n",
       " 'became': 79,\n",
       " 'man—': 80,\n",
       " 'small': 81,\n",
       " 'book': 82,\n",
       " 'pocket': 83,\n",
       " 'it': 84,\n",
       " 'was': 85,\n",
       " 'wonder': 86,\n",
       " 'if': 87,\n",
       " 'sold': 88,\n",
       " 'his': 89,\n",
       " 'farm': 90,\n",
       " 'as': 91,\n",
       " 'stardials': 92,\n",
       " 'hinted': 93,\n",
       " 'morn': 94,\n",
       " 'well': 95,\n",
       " 'may': 96,\n",
       " 'stars': 97,\n",
       " 'mute': 98,\n",
       " 'lavas': 99,\n",
       " 'that': 100,\n",
       " 'restlessly': 101,\n",
       " 'roll': 102,\n",
       " 'why': 103,\n",
       " 'seats': 104,\n",
       " 'on': 105,\n",
       " 'cellar': 106,\n",
       " 'wall': 107,\n",
       " 'for': 108,\n",
       " 'hog': 109,\n",
       " 'reeve': 110,\n",
       " 'march': 111,\n",
       " 'meeting': 112,\n",
       " 'warren': 113,\n",
       " 'one': 114,\n",
       " 'bearing': 115,\n",
       " 'done': 116,\n",
       " 'detail': 117,\n",
       " 'merrily': 118,\n",
       " 'live': 119,\n",
       " 'and': 120,\n",
       " 'never': 121,\n",
       " 'could': 122,\n",
       " 'have': 123,\n",
       " 'thing': 124,\n",
       " 'did': 125,\n",
       " 'been': 126,\n",
       " 'acquainted': 127,\n",
       " 'night': 128,\n",
       " 'this': 129,\n",
       " 'standing': 130,\n",
       " 'motionless': 131,\n",
       " 'upon': 132,\n",
       " 'golden': 133,\n",
       " 'evil': 134,\n",
       " 'things': 135,\n",
       " 'robes': 136,\n",
       " 'sorrow': 137,\n",
       " 'see': 138,\n",
       " 'any': 139,\n",
       " 'mormon': 140,\n",
       " 'swimming': 141,\n",
       " 'show': 142,\n",
       " 'are': 143,\n",
       " 'remembered': 144,\n",
       " 'dank': 145,\n",
       " 'tarn': 146,\n",
       " 'auber': 147,\n",
       " 'love': 148,\n",
       " 'her': 149,\n",
       " 'luminous': 150,\n",
       " 'eyes': 151,\n",
       " 'ready': 152,\n",
       " 'outsiders': 153,\n",
       " 'is': 154,\n",
       " 'owing': 155,\n",
       " 'lyre': 156,\n",
       " 'from': 157,\n",
       " 'us': 158,\n",
       " 'life': 159,\n",
       " 'common': 160,\n",
       " 'which': 161,\n",
       " 'doth': 162,\n",
       " 'lie': 163,\n",
       " 'folks': 164,\n",
       " 'like': 165,\n",
       " 'business': 166,\n",
       " 'mustnt': 167,\n",
       " 'bear': 168,\n",
       " 'too': 169,\n",
       " 'hard': 170,\n",
       " 'new': 171,\n",
       " 'comers': 172,\n",
       " 'thats': 173,\n",
       " 'sit': 174,\n",
       " 'up': 175,\n",
       " 'dark': 176,\n",
       " 'he': 177,\n",
       " 'liked': 178,\n",
       " 'everything': 179,\n",
       " 'made': 180,\n",
       " 'him': 181,\n",
       " 'do': 182,\n",
       " 'when': 183,\n",
       " 'who': 184,\n",
       " 'would': 185,\n",
       " 'come': 186,\n",
       " 'seeking': 187,\n",
       " 'hampshire': 188,\n",
       " 'ways': 189,\n",
       " 'can': 190,\n",
       " 'hardly': 191,\n",
       " 'among': 192,\n",
       " 'buttons': 193,\n",
       " 'poured': 194,\n",
       " 'out': 195,\n",
       " 'lap': 196,\n",
       " 'astartes': 197,\n",
       " 'bediamonded': 198,\n",
       " 'crescent': 199,\n",
       " 'uncommonly': 200,\n",
       " 'deep': 201,\n",
       " 'snow': 202,\n",
       " 'has': 203,\n",
       " 'think': 204,\n",
       " 'must': 205,\n",
       " 'right': 206,\n",
       " 'leave': 207,\n",
       " 'profanation': 208,\n",
       " 'by': 209,\n",
       " 'your': 210,\n",
       " 'turned': 211,\n",
       " 'them': 212,\n",
       " 'world': 213,\n",
       " 'try': 214,\n",
       " 'fathom': 215,\n",
       " 'saved': 216,\n",
       " 'going': 217,\n",
       " 'staid': 218,\n",
       " 'shelter': 219,\n",
       " 'cannot': 220,\n",
       " 'write': 221,\n",
       " 'speak': 222,\n",
       " 'sparkling': 223,\n",
       " 'evermore': 224,\n",
       " 'rests': 225,\n",
       " 'always': 226,\n",
       " 'cut': 227,\n",
       " 'off': 228,\n",
       " 'dont': 229,\n",
       " 'mean': 230,\n",
       " 'just': 231,\n",
       " 'skulls': 232,\n",
       " 'rogers': 233,\n",
       " 'rangers': 234,\n",
       " 'stood': 235,\n",
       " 'please': 236,\n",
       " 'kitchen': 237,\n",
       " 'chimney': 238,\n",
       " 'wanted': 239,\n",
       " 'put': 240,\n",
       " 'hadnt': 241,\n",
       " 'suspected': 242,\n",
       " 'where': 243,\n",
       " 'were': 244,\n",
       " 'bells': 245,\n",
       " 'vacuum': 246,\n",
       " 'filmy': 247,\n",
       " 'heaven': 248,\n",
       " 'tower': 249,\n",
       " 'said': 250,\n",
       " 'written': 251,\n",
       " 'sweet': 252,\n",
       " 'sister': 253,\n",
       " 'italian': 254,\n",
       " 'tones': 255,\n",
       " 'only': 256,\n",
       " 'murmured': 257,\n",
       " 'beauty': 258,\n",
       " 'our': 259,\n",
       " 'god': 260,\n",
       " 'those': 261,\n",
       " 'alone': 262,\n",
       " 'oh': 263,\n",
       " 'hawks': 264,\n",
       " 'since': 265,\n",
       " 'chickentime': 266,\n",
       " 'lady': 267,\n",
       " 'spell': 268,\n",
       " 'hold': 269,\n",
       " 'they': 270,\n",
       " 'tears': 271,\n",
       " 'miraculous': 272,\n",
       " 'son': 273,\n",
       " 'wouldnt': 274,\n",
       " 'want': 275,\n",
       " 'man': 276,\n",
       " 'killed': 277,\n",
       " 'instead': 278,\n",
       " 'fist': 279,\n",
       " 'buried': 280,\n",
       " 'bushy': 281,\n",
       " 'hide': 282,\n",
       " 'will': 283,\n",
       " 'half': 284,\n",
       " 'believe': 285,\n",
       " 'wild': 286,\n",
       " 'fraught': 287,\n",
       " 'know': 288,\n",
       " 'might': 289,\n",
       " 'still': 290,\n",
       " 'cousins': 291,\n",
       " 'simply': 292,\n",
       " 'lay': 293,\n",
       " 'someone': 294,\n",
       " 'now': 295,\n",
       " 'then': 296,\n",
       " 'today': 297,\n",
       " 'redlitten': 298,\n",
       " 'windows': 299,\n",
       " 'pipes': 300,\n",
       " 'smoking': 301,\n",
       " 'jug': 302,\n",
       " 'its': 303,\n",
       " 'granny': 304,\n",
       " 'speaking': 305,\n",
       " 'dunnow': 306,\n",
       " 'headed': 307,\n",
       " 'for—': 308,\n",
       " 'sadder': 309,\n",
       " 'science': 310,\n",
       " 'true': 311,\n",
       " 'daughter': 312,\n",
       " 'old': 313,\n",
       " 'time': 314,\n",
       " 'thou': 315,\n",
       " 'art': 316,\n",
       " 'nor': 317,\n",
       " 'way': 318,\n",
       " 'thinking': 319,\n",
       " 'mother': 320,\n",
       " 'bones': 321,\n",
       " 'skeleton': 322,\n",
       " 'hearthistories': 323,\n",
       " 'seemed': 324,\n",
       " 'enwritten': 325,\n",
       " 'board': 326,\n",
       " 'laid': 327,\n",
       " 'walk': 328,\n",
       " 'dryshod': 329,\n",
       " 'pale': 330,\n",
       " 'door': 331,\n",
       " 'bead': 332,\n",
       " 'silver': 333,\n",
       " 'water': 334,\n",
       " 'less': 335,\n",
       " 'sybilic': 336,\n",
       " 'splendor': 337,\n",
       " 'beaming': 338,\n",
       " 'little': 339,\n",
       " 'horse': 340,\n",
       " 'queer': 341,\n",
       " 'israfelis': 342,\n",
       " 'fire': 343,\n",
       " 'got': 344,\n",
       " 'excuse': 345,\n",
       " 'ask': 346,\n",
       " 'window': 347,\n",
       " 'halfway': 348,\n",
       " 'fought': 349,\n",
       " 'battle': 350,\n",
       " 'past': 351,\n",
       " 'lion': 352,\n",
       " 'couldnt': 353,\n",
       " 'shall': 354,\n",
       " 'telling': 355,\n",
       " 'sigh': 356,\n",
       " 'conquered': 357,\n",
       " 'scruples': 358,\n",
       " 'gloom': 359,\n",
       " 'another': 360,\n",
       " 'bedroom': 361,\n",
       " 'how': 362,\n",
       " 'many': 363,\n",
       " 'scenes': 364,\n",
       " 'departed': 365,\n",
       " 'bliss': 366,\n",
       " 'lost': 367,\n",
       " 'himself': 368,\n",
       " 'tongue': 369,\n",
       " 'pauses': 370,\n",
       " 'misty': 371,\n",
       " 'mid': 372,\n",
       " 'region': 373,\n",
       " 'weir': 374,\n",
       " 'springs': 375,\n",
       " 'neer': 376,\n",
       " 'flow': 377,\n",
       " 'save': 378,\n",
       " 'thee': 379,\n",
       " 'paused': 380,\n",
       " 'looked': 381,\n",
       " 'coming': 382,\n",
       " 'choice': 383,\n",
       " 'fever': 384,\n",
       " 'moonbeam': 385,\n",
       " 'hangs': 386,\n",
       " 'oer': 387,\n",
       " 'place': 388,\n",
       " 'john': 389,\n",
       " 'cutting': 390,\n",
       " 'trees': 391,\n",
       " 'israfel': 392,\n",
       " 'ah': 393,\n",
       " 'nights': 394,\n",
       " 'year': 395,\n",
       " 'their': 396,\n",
       " 'tatters': 397,\n",
       " 'hung': 398,\n",
       " 'barb': 399,\n",
       " 'thorn': 400,\n",
       " '‘tis': 401,\n",
       " 'vault': 402,\n",
       " 'ulalume': 403,\n",
       " 'streams': 404,\n",
       " 'turrets': 405,\n",
       " 'silently': 406,\n",
       " 'didst': 407,\n",
       " 'glide': 408,\n",
       " 'away': 409,\n",
       " 'thine': 410,\n",
       " 'remained': 411,\n",
       " 'along': 412,\n",
       " 'ramparts': 413,\n",
       " 'plumed': 414,\n",
       " 'pallid': 415,\n",
       " 'ive': 416,\n",
       " 'shouldnt': 417,\n",
       " 'married': 418,\n",
       " 'daylight': 419,\n",
       " 'birth': 420,\n",
       " 'seraphic': 421,\n",
       " 'glancing': 422,\n",
       " 'celebrating': 423,\n",
       " 'strange': 424,\n",
       " 'home': 425,\n",
       " 'kept': 426,\n",
       " 'remembering': 427,\n",
       " 'used': 428,\n",
       " 'sing': 429,\n",
       " 'toteroad': 430,\n",
       " 'bed': 431,\n",
       " 'wrote': 432,\n",
       " 'sign': 433,\n",
       " 'spose': 434,\n",
       " 'mallice': 435,\n",
       " 'huse': 436,\n",
       " 'groan': 437,\n",
       " 'mount': 438,\n",
       " 'yaanek': 439,\n",
       " 'oho': 440,\n",
       " 'smoke': 441,\n",
       " 'rolled': 442,\n",
       " 'inside': 443,\n",
       " 'sockets': 444,\n",
       " 'cypress': 445,\n",
       " 'psyche': 446,\n",
       " 'soul': 447,\n",
       " 'plumes': 448,\n",
       " 'till': 449,\n",
       " 'trailed': 450,\n",
       " 'dust': 451,\n",
       " 'left': 452,\n",
       " 'open': 453,\n",
       " 'cool': 454,\n",
       " 'room': 455,\n",
       " 'domes': 456,\n",
       " 'spires': 457,\n",
       " 'kingly': 458,\n",
       " 'halls': 459,\n",
       " 'gazing': 460,\n",
       " 'entranced': 461,\n",
       " 'adown': 462,\n",
       " 'gorgeous': 463,\n",
       " 'vista': 464,\n",
       " 'hall': 465,\n",
       " 'finished': 466,\n",
       " 'look': 467,\n",
       " 'treat': 468,\n",
       " 'guide': 469,\n",
       " 'due': 470,\n",
       " 'respect': 471,\n",
       " 'crooking': 472,\n",
       " 'trillium': 473,\n",
       " 'pen': 474,\n",
       " 'falls': 475,\n",
       " 'powerless': 476,\n",
       " 'shivering': 477,\n",
       " 'hand': 478,\n",
       " 'yes': 479,\n",
       " 'stark': 480,\n",
       " 'summer': 481,\n",
       " 'dream': 482,\n",
       " 'beneath': 483,\n",
       " 'tamarind': 484,\n",
       " 'tree': 485,\n",
       " 'brought': 486,\n",
       " 'back': 487,\n",
       " 'into': 488,\n",
       " 'name': 489,\n",
       " 'winds': 490,\n",
       " 'woo': 491,\n",
       " 'together': 492,\n",
       " 'pull': 493,\n",
       " 'apart': 494,\n",
       " 'tote': 495,\n",
       " 'road': 496,\n",
       " 'clearing': 497,\n",
       " 'lived': 498,\n",
       " 'wings': 499,\n",
       " 'until': 500,\n",
       " 'sometimes': 501,\n",
       " 'wander': 502,\n",
       " 'beaten': 503,\n",
       " 'fence': 504,\n",
       " 'flowers': 505,\n",
       " 'hens': 506,\n",
       " 'range': 507,\n",
       " 'holy': 508,\n",
       " 'throne': 509,\n",
       " 'above': 510,\n",
       " 'lane': 511,\n",
       " 'yet': 512,\n",
       " 'realms': 513,\n",
       " 'boreal': 514,\n",
       " 'pole': 515,\n",
       " 'jupiter': 516,\n",
       " 'fervor': 517,\n",
       " 'lute': 518,\n",
       " 'eddy': 519,\n",
       " 'over': 520,\n",
       " 'toppling': 521,\n",
       " 'weak': 522,\n",
       " 'showed': 523,\n",
       " 'arthur': 524,\n",
       " 'amy': 525,\n",
       " 'signs': 526,\n",
       " 'enough': 527,\n",
       " 'go': 528,\n",
       " 'mowing': 529,\n",
       " 'field': 530,\n",
       " 'joe': 531,\n",
       " 'slippery': 532,\n",
       " 'slope': 533,\n",
       " 'start': 534,\n",
       " 'lately': 535,\n",
       " 'slept': 536,\n",
       " 'apathy': 537,\n",
       " 'same': 538,\n",
       " 'smarty': 539,\n",
       " 'grave': 540,\n",
       " 'other': 541,\n",
       " 'strangely': 542,\n",
       " 'anything': 543,\n",
       " 'wish': 544,\n",
       " 'give': 545,\n",
       " 'tangle': 546,\n",
       " 'withered': 547,\n",
       " 'weeds': 548,\n",
       " 'facts': 549,\n",
       " 'fancied': 550,\n",
       " 'six': 551,\n",
       " 'oclock': 552,\n",
       " 'tis': 553,\n",
       " 'ice': 554,\n",
       " 'cake': 555,\n",
       " 'seen': 556,\n",
       " 'make': 557,\n",
       " 'truest': 558,\n",
       " 'most': 559,\n",
       " 'fervently': 560,\n",
       " 'devoted': 561,\n",
       " 'im': 562,\n",
       " 'greatly': 563,\n",
       " 'afraid': 564,\n",
       " 'position': 565,\n",
       " 'close': 566,\n",
       " 'scurf': 567,\n",
       " 'plants': 568,\n",
       " 'weary': 569,\n",
       " 'overheated': 570,\n",
       " 'two': 571,\n",
       " 'converging': 572,\n",
       " 'slides': 573,\n",
       " 'avalanches': 574,\n",
       " 'shining': 575,\n",
       " 'stone': 576,\n",
       " 'lead': 577,\n",
       " 'unprotected': 578,\n",
       " 'glass': 579,\n",
       " 'having': 580,\n",
       " 'eased': 581,\n",
       " 'heart': 582,\n",
       " 'copy': 583,\n",
       " 'am': 584,\n",
       " 'myself': 585,\n",
       " 'does': 586,\n",
       " 'perhaps': 587,\n",
       " 'three': 588,\n",
       " 'memories': 589,\n",
       " 'radiant': 590,\n",
       " 'hours': 591,\n",
       " 'father': 592,\n",
       " 'mine': 593,\n",
       " 'nighttime': 594,\n",
       " 'town': 595,\n",
       " 'house': 596,\n",
       " 'village': 597,\n",
       " 'ministers': 598,\n",
       " 'slave': 599,\n",
       " 'ryans': 600,\n",
       " 'hill': 601,\n",
       " 'thought': 602,\n",
       " 'twas': 603,\n",
       " 'meddle': 604,\n",
       " 'fate': 605,\n",
       " 'far': 606,\n",
       " 'kneel': 607,\n",
       " 'theres': 608,\n",
       " 'dead': 609,\n",
       " 'keeping': 610,\n",
       " 'hell': 611,\n",
       " 'knees': 612,\n",
       " 'unless': 613,\n",
       " 'hellforleather': 614,\n",
       " 'cosmic': 615,\n",
       " 'motes': 616,\n",
       " 'lest': 617,\n",
       " 'truant': 618,\n",
       " 'lets': 619,\n",
       " 'wasnt': 620,\n",
       " 'wentworth': 621,\n",
       " 'beside': 622,\n",
       " 'stands': 623,\n",
       " 'bare': 624,\n",
       " 'suddenly': 625,\n",
       " 'flung': 626,\n",
       " 'wide': 627,\n",
       " 'walked': 628,\n",
       " 'sunday': 629,\n",
       " 'after': 630,\n",
       " 'church': 631,\n",
       " 'get': 632,\n",
       " 'train': 633,\n",
       " 'talk': 634,\n",
       " 'serious': 635,\n",
       " 'sober': 636,\n",
       " 'expanding': 637,\n",
       " 'asked': 638,\n",
       " 'hopes': 639,\n",
       " 'ten': 640,\n",
       " 'million': 641,\n",
       " 'lizards': 642,\n",
       " 'wouldst': 643,\n",
       " 'loved': 644,\n",
       " 'caught': 645,\n",
       " 'lizard': 646,\n",
       " 'tail': 647,\n",
       " 'smash': 648,\n",
       " 'wake': 649,\n",
       " 'drawn': 650,\n",
       " 'hearts': 651,\n",
       " 'passion': 652,\n",
       " 'tone': 653,\n",
       " 'ripples': 654,\n",
       " 'curl': 655,\n",
       " 'alas': 656,\n",
       " 'greenest': 657,\n",
       " 'valleys': 658,\n",
       " 'threw': 659,\n",
       " 'didnt': 660,\n",
       " 'enter': 661,\n",
       " 'between': 662,\n",
       " 'north': 663,\n",
       " 'pole—': 664,\n",
       " 'shrines': 665,\n",
       " 'palaces': 666,\n",
       " 'towers': 667,\n",
       " 'mica': 668,\n",
       " 'sheets': 669,\n",
       " 'big': 670,\n",
       " 'plateglass': 671,\n",
       " 'immemorial': 672,\n",
       " 'lefts': 673,\n",
       " 'bigger': 674,\n",
       " 'harness': 675,\n",
       " 'gall': 676,\n",
       " 'ear': 677,\n",
       " 'pianos': 678,\n",
       " 'vigor': 679,\n",
       " 'mind': 680,\n",
       " 'stand': 681,\n",
       " 'whats': 682,\n",
       " 'use': 683,\n",
       " 'talking': 684,\n",
       " 'earthly': 685,\n",
       " 'weather': 686,\n",
       " 'describing': 687,\n",
       " 'rings': 688,\n",
       " 'lantern': 689,\n",
       " 'tasted': 690,\n",
       " 'desire': 691,\n",
       " 'lighting': 692,\n",
       " 'lonely': 693,\n",
       " 'pathway': 694,\n",
       " 'fullorbed': 695,\n",
       " 'moon': 696,\n",
       " 'soaring': 697,\n",
       " 'gave': 698,\n",
       " 'pretense': 699,\n",
       " 'covered': 700,\n",
       " 'chandelier': 701,\n",
       " 'cloud': 702,\n",
       " 'obscured': 703,\n",
       " 'sky': 704,\n",
       " 'looks': 705,\n",
       " 'surprised': 706,\n",
       " 'end': 707,\n",
       " 'swarm': 708,\n",
       " 'ran': 709,\n",
       " 'scuttled': 710,\n",
       " 'fast': 711,\n",
       " 'anywhere': 712,\n",
       " 'both': 713,\n",
       " 'united': 714,\n",
       " 'strengths': 715,\n",
       " 'before': 716,\n",
       " 'face': 717,\n",
       " 'ungodly': 718,\n",
       " 'nova': 719,\n",
       " 'often': 720,\n",
       " 'forget': 721,\n",
       " 'lone': 722,\n",
       " 'matter': 723,\n",
       " 'times': 724,\n",
       " 'cried': 725,\n",
       " 'surely': 726,\n",
       " 'october': 727,\n",
       " 'reason': 728,\n",
       " 'property': 729,\n",
       " 'allowed': 730,\n",
       " 'upside': 731,\n",
       " 'dyou': 732,\n",
       " 'person': 733,\n",
       " 'related': 734,\n",
       " 'herself': 735,\n",
       " 'despite': 736,\n",
       " 'whom': 737,\n",
       " 'absence': 738,\n",
       " 'eye': 739,\n",
       " 'while': 740,\n",
       " 'even': 741,\n",
       " 'meridian': 742,\n",
       " 'glare': 743,\n",
       " 'day': 744,\n",
       " 'footstep': 745,\n",
       " 'stirred': 746,\n",
       " 'hated': 747,\n",
       " 'idled': 748,\n",
       " 'some': 749,\n",
       " 'she': 750,\n",
       " 'nodded': 751,\n",
       " 'future': 752,\n",
       " 'shine': 753,\n",
       " 'blow': 754,\n",
       " 'grassy': 755,\n",
       " 'places': 756,\n",
       " 'bleak': 757,\n",
       " 'wetelbowed': 758,\n",
       " 'wetkneed': 759,\n",
       " 'find': 760,\n",
       " 'fountain': 761,\n",
       " 'takes': 762,\n",
       " 'voted': 763,\n",
       " 'ever': 764,\n",
       " 'boring': 765,\n",
       " 'climbing': 766,\n",
       " 'outdoors': 767,\n",
       " '2o3': 768,\n",
       " 'stay': 769,\n",
       " 'attic': 770,\n",
       " 'went': 771,\n",
       " 'buttonbox': 772,\n",
       " 'undivided': 773,\n",
       " 'wheels': 774,\n",
       " 'hang': 775,\n",
       " 'birds': 776,\n",
       " 'outer': 777,\n",
       " 'windowsill': 778,\n",
       " 'lair': 779,\n",
       " 'trust': 780,\n",
       " 'youve': 781,\n",
       " 'sulphurous': 782,\n",
       " 'currents': 783,\n",
       " 'goodbye': 784,\n",
       " 'such': 785,\n",
       " 'case': 786,\n",
       " 'brushed': 787,\n",
       " 'across': 788,\n",
       " 'suns': 789,\n",
       " 'wizard': 790,\n",
       " 'whose': 791,\n",
       " 'hope': 792,\n",
       " 'died': 793,\n",
       " 'soulandbody': 794,\n",
       " 'scars': 795,\n",
       " 'sink': 796,\n",
       " 'under': 797,\n",
       " 'being': 798,\n",
       " 'wife': 799,\n",
       " 'desperate': 800,\n",
       " 'energy': 801,\n",
       " 't': 802,\n",
       " 'hath': 803,\n",
       " 'isnt': 804,\n",
       " 'worth': 805,\n",
       " 'mortgage': 806,\n",
       " 'reconnoitre': 807,\n",
       " 'johns': 808,\n",
       " 'threatener': 809,\n",
       " 'blandishments': 810,\n",
       " 'seem': 811,\n",
       " 'defied': 812,\n",
       " 'happen': 813,\n",
       " 'prefer': 814,\n",
       " 'tamed': 815,\n",
       " 'primeval': 816,\n",
       " 'wood': 817,\n",
       " 'bade': 818,\n",
       " 'pause': 819,\n",
       " 'gardengate': 820,\n",
       " 'alls': 821,\n",
       " 'break': 822,\n",
       " 'job': 823,\n",
       " 'whir': 824,\n",
       " 'transfixed': 825,\n",
       " 'mountain': 826,\n",
       " 'slopes': 827,\n",
       " 'almost': 828,\n",
       " 'erect': 829,\n",
       " 'young': 830,\n",
       " 'roar': 831,\n",
       " 'given': 832,\n",
       " 'else': 833,\n",
       " 'magic': 834,\n",
       " 'sun': 835,\n",
       " 'tinkling': 836,\n",
       " 'throats': 837,\n",
       " 'houses': 838,\n",
       " 'shoeing': 839,\n",
       " 'white': 840,\n",
       " 'twice': 841,\n",
       " 'around': 842,\n",
       " 'leaves': 843,\n",
       " 'withering': 844,\n",
       " 'sere': 845,\n",
       " 'geese': 846,\n",
       " 'lake': 847,\n",
       " 'storm': 848,\n",
       " 'race': 849,\n",
       " 'great': 850,\n",
       " 'auk': 851,\n",
       " 'i—': 852,\n",
       " 'sincere': 853,\n",
       " 'reply': 854,\n",
       " 'care': 855,\n",
       " 'replied': 856,\n",
       " 'nothing': 857,\n",
       " 'dreaming': 858,\n",
       " 'hear': 859,\n",
       " 'angel': 860,\n",
       " 'ours': 861,\n",
       " 'toward': 862,\n",
       " 'against': 863,\n",
       " 'blue': 864,\n",
       " 'hands': 865,\n",
       " 'gold': 866,\n",
       " 'within': 867,\n",
       " 'earth': 868,\n",
       " 'selfclear': 869,\n",
       " 'nose': 870,\n",
       " 'sos': 871,\n",
       " 'chin': 872,\n",
       " 'vast': 873,\n",
       " 'nine': 874,\n",
       " 'rock': 875,\n",
       " 'rare': 876,\n",
       " 'song': 877,\n",
       " 'shes': 878,\n",
       " 'wrong': 879,\n",
       " 'saw': 880,\n",
       " 'throw': 881,\n",
       " 'hoe': 882,\n",
       " 'fly': 883,\n",
       " 'lying': 884,\n",
       " 'fell': 885,\n",
       " 'rejected': 886,\n",
       " 'neighbour': 887,\n",
       " 'longer': 888,\n",
       " 'feel': 889,\n",
       " 'hurried': 890,\n",
       " 'tutelar': 891,\n",
       " 'shrine': 892,\n",
       " 'attempting': 893,\n",
       " 'stray': 894,\n",
       " 'found': 895,\n",
       " 'id': 896,\n",
       " 'better': 897,\n",
       " 'purified': 898,\n",
       " 'electric': 899,\n",
       " 'skies': 900,\n",
       " 'ashen': 901,\n",
       " 'otherwise': 902,\n",
       " 'fall': 903,\n",
       " 'legs': 904,\n",
       " 'baby': 905,\n",
       " 'sovereignty': 906,\n",
       " 'ancient': 907,\n",
       " 'lore': 908,\n",
       " 'flight': 909,\n",
       " 'traveler': 910,\n",
       " 'grace': 911,\n",
       " 'manages': 912,\n",
       " 'keep': 913,\n",
       " 'upper': 914,\n",
       " 'doesnt': 915,\n",
       " 'yankees': 916,\n",
       " 'havent': 917,\n",
       " 'set': 918,\n",
       " 'brushing': 919,\n",
       " 'chalky': 920,\n",
       " 'skull': 921,\n",
       " 'fingers': 922,\n",
       " 'sure': 923,\n",
       " 'aright': 924,\n",
       " 'explain': 925,\n",
       " 'thered': 926,\n",
       " 'boston': 927,\n",
       " 'people': 928,\n",
       " 'either': 929,\n",
       " 'power': 930,\n",
       " 'seems': 931,\n",
       " 'undone': 932,\n",
       " 'disappeared': 933,\n",
       " 'ended': 934,\n",
       " 'empty': 935,\n",
       " 'several': 936,\n",
       " 'marrying': 937,\n",
       " 'earnest': 938,\n",
       " 'appears': 939,\n",
       " 'men': 940,\n",
       " 'mistake': 941,\n",
       " 'tried': 942,\n",
       " 'dropped': 943,\n",
       " 'feet': 944,\n",
       " 'backs': 945,\n",
       " 'safely': 946,\n",
       " 'gleaming': 947,\n",
       " 'guess': 948,\n",
       " 'youd': 949,\n",
       " 'ecstasies': 950,\n",
       " 'ceasing': 951,\n",
       " 'hymns': 952,\n",
       " 'attend': 953,\n",
       " 'truth': 954,\n",
       " 'housework': 955,\n",
       " 'besides': 956,\n",
       " 'lo': 957,\n",
       " 'death': 958,\n",
       " 'reard': 959,\n",
       " 'sounds': 960,\n",
       " 'dry': 961,\n",
       " 'rattling': 962,\n",
       " 'shutter': 963,\n",
       " 'gone': 964,\n",
       " 'course': 965,\n",
       " 'worn': 966,\n",
       " 'skin': 967,\n",
       " 'flew': 968,\n",
       " 'brightly': 969,\n",
       " 'hillside': 970,\n",
       " 'fountains': 971,\n",
       " 'overflow': 972,\n",
       " 'monarch': 973,\n",
       " 'thoughts': 974,\n",
       " 'dominion': 975,\n",
       " 'admiring': 976,\n",
       " 'natures': 977,\n",
       " 'universal': 978,\n",
       " 'recognize': 979,\n",
       " 'post': 980,\n",
       " 'ones': 981,\n",
       " 'huh': 982,\n",
       " 'bathtub': 983,\n",
       " 'lifts': 984,\n",
       " 'gaunt': 985,\n",
       " 'luxuriating': 986,\n",
       " 'beast': 987,\n",
       " 'garden': 988,\n",
       " 'ground': 989,\n",
       " 'spirit': 990,\n",
       " 'communing': 991,\n",
       " 'angels': 992,\n",
       " 'thus': 993,\n",
       " 'memory': 994,\n",
       " 'few': 995,\n",
       " 'peckerfretted': 996,\n",
       " 'apple': 997,\n",
       " 'behind': 998,\n",
       " 'headboard': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2510"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data into integer format \n",
    "train_text_int = []\n",
    "test_text_int = []\n",
    "\n",
    "for text in train_text: \n",
    "    tokens = text.split() \n",
    "\n",
    "    # map each token to its corresponding word, line is array of ints \n",
    "    line_as_int = [word2idx[token] for token in tokens] \n",
    "\n",
    "    # array of ints \n",
    "    train_text_int.append(line_as_int)\n",
    "\n",
    "for text in test_text: \n",
    "    tokens = text.split() \n",
    "\n",
    "    # possible that not every word in train appears in test, if it doesn't appear => return default value 0 (<unk>)\n",
    "    line_as_int = [word2idx.get(token, 0) for token in tokens] \n",
    "    test_text_int.append(line_as_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[129, 371, 372, 373, 2, 374],\n",
       " [7, 375, 100, 376, 125, 377],\n",
       " [378, 256, 379, 120, 53, 35, 380, 35, 381],\n",
       " [303, 382, 175, 7, 62, 84, 25, 303, 383],\n",
       " [7, 13, 384, 209, 3, 385, 100, 386, 387]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text_int[100:105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize A and pi matrices for both classes \n",
    "# size = number of different words (to satisfy current_word, last_word match in the indexes)\n",
    "V = len(word2idx) \n",
    "\n",
    "# as many models as classes (here edgar and robert)\n",
    "A0 = np.ones((V, V))\n",
    "\n",
    "# probability that a word will be at the start of a sentence \n",
    "pi0 = np.ones(V) \n",
    "\n",
    "A1 = np.ones((V, V))\n",
    "pi1 = np.ones(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute counts for A and pi, A/pi object => modifications will be remembered\n",
    "def compute_counts(text_as_int, A, pi): \n",
    "    for tokens in text_as_int: \n",
    "        last_idx = None\n",
    "\n",
    "        for idx in tokens: \n",
    "            if last_idx is None: \n",
    "                # it's the first word in a sentence\n",
    "                pi[idx] += 1 \n",
    "            else: \n",
    "                # the last word exists, so count a transition \n",
    "                # between last_word, current_wod\n",
    "                A[last_idx, idx] += 1 \n",
    "        \n",
    "            # update the last idx\n",
    "            last_idx = idx \n",
    "\n",
    "# will still pass only train_text_int to the function \n",
    "# zip only needed to determine if y == 0 \n",
    "compute_counts([t for t, y in zip(train_text_int, Ytrain) if y == 0 ], A0, pi0)\n",
    "compute_counts([t for t, y in zip(train_text_int, Ytrain) if y == 1 ], A1, pi1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize A and pi so they are valid probability matrices \n",
    "# Create probability of each last_word, current_word combination \n",
    "A0 /= A0.sum(axis=1, keepdims=True) \n",
    "\n",
    "# it will sum to 1 (100%)\n",
    "pi0 /= pi0.sum() \n",
    "\n",
    "\n",
    "# one markov matrix per class (here are 2, one for poe and one for frost)\n",
    "A1 /= A1.sum(axis=1, keepdims=True) \n",
    "pi1 /= pi1.sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log A and pi since we don't need the actual probs \n",
    "# multiplication will remain above 0 \n",
    "logA0 = np.log(A0) \n",
    "logpi0 = np.log(pi0) \n",
    "\n",
    "logA1 = np.log(A1) \n",
    "logpi1 = np.log(pi1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6557275541795665, 0.3442724458204334)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute priors, sentences written by frost and poe respectively\n",
    "count0 = sum(y == 0 for y in Ytrain) \n",
    "count1 = sum(y == 1 for y in Ytrain) \n",
    "\n",
    "# total written by both together\n",
    "total = len(Ytrain)\n",
    "\n",
    "# chance a sentence is written by poe or frost \n",
    "p0 = count0 / total \n",
    "p1 = count1 / total \n",
    "\n",
    "# log because it will be multiplied and will become too small to handle\n",
    "logp0 = np.log(p0) \n",
    "logp1 = np.log(p1)\n",
    "\n",
    "# imbalanced\n",
    "p0, p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build classifier \n",
    "class Classifier: \n",
    "    def __init__(self, logAs, logpis, logpriors) -> None:\n",
    "        # array of matrices\n",
    "        self.logAs = logAs\n",
    "\n",
    "        # array of arrays \n",
    "        self.logpis = logpis\n",
    "\n",
    "        # array, the probability of each class (65% for frost here)\n",
    "        self.logpriors = logpriors\n",
    "\n",
    "\n",
    "        self.K = len(logpriors) # number of classes\n",
    "\n",
    "    # line of text and which markov model to use\n",
    "    def _compute_log_likelihood(self, input_, class_): \n",
    "        # take log values from the precomputed matrix\n",
    "        logA = self.logAs[class_]\n",
    "        logpi = self.logpis[class_]\n",
    "\n",
    "        # loop through the idx words in a sentence \n",
    "        last_idx = None\n",
    "        logprob  = 0 \n",
    "        for idx in input_: \n",
    "            if last_idx is None: \n",
    "                # it's the first token (first word)\n",
    "                logprob += logpi[idx]\n",
    "            else: \n",
    "                # state transition matrix at index lastword, current word \n",
    "                logprob += logA[last_idx, idx]\n",
    "\n",
    "            # update last_idx\n",
    "            last_idx = idx\n",
    "\n",
    "        # probability of this sequence (whole sentence)\n",
    "        return logprob\n",
    "    \n",
    "    # pass list of sentences\n",
    "    def predict(self, inputs): \n",
    "        # store predictions (1 elem per sentece)\n",
    "        predictions = np.zeros(len(inputs))\n",
    "\n",
    "        for i, input_ in enumerate(inputs): \n",
    "            # loop over all classes and compute the prob of the sentence for each class, save in array\n",
    "            # at index 0 will be the probability of being frost \n",
    "            posteriors = [self._compute_log_likelihood(input_, c) + self.logpriors[c] for c in range(self.K)]\n",
    "\n",
    "            # take the index of the highest probability \n",
    "            pred = np.argmax(posteriors) \n",
    "\n",
    "            # store in the array of all sentences\n",
    "            predictions[i] = pred \n",
    "\n",
    "        return  predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each array must be in order, index in array = class\n",
    "clf = Classifier([logA0, logA1], [logpi0, logpi1], [logp0, logp1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9950464396284829\n"
     ]
    }
   ],
   "source": [
    "# trains the model using the precomputed A and pi matrices\n",
    "Ptrain = clf.predict(train_text_int)\n",
    "\n",
    "print(f\"Train accuracy: {np.mean(Ptrain == Ytrain)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.8256029684601113\n"
     ]
    }
   ],
   "source": [
    "# sentences already vectorized\n",
    "Ptest = clf.predict(test_text_int) \n",
    "\n",
    "print(f\"Test acc: {np.mean(Ptest == Ytest)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1059,    0],\n",
       "       [   8,  548]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "cm = confusion_matrix(Ytrain, Ptrain) \n",
    "cm\n",
    "\n",
    "# classified as frost (truly frost, truly poe)\n",
    "# classified as poe (truly frost, truly poe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[365,  12],\n",
       "       [ 82,  80]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_test = confusion_matrix(Ytest, Ptest)\n",
    "cm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9927536231884058"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(Ytrain, Ptrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6299212598425197"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(Ytest, Ptest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
